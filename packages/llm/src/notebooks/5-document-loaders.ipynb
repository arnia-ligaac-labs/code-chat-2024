{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loaders\n",
    "\n",
    "- it is not scalable to manually hardcode documents with all of the factual up to date data and pass to model\n",
    "- we should dynamically load data from a variety of sources\n",
    "\n",
    "There are two broad type of loaders:\n",
    " - file loaders (extracts from variety of file formats on local filesystem [CSV,XML,JSON,PDF,etc])\n",
    " - web loaders (extracts from variety of web platforms [Github, Playwright, Puppeteer,etc])\n",
    "\n",
    "They all exist in the `@langchain/community/document_loaders` location.\n",
    "\n",
    "We will be using a web scraper to access [LCEL](https://python.langchain.com/v0.1/docs/expression_language/) page and extract content and convert it to useable documents. Namely `CheerioWebBaseLoader` from `@langchain/community/document_loaders`\n",
    "\n",
    "`CheerioWebBaseLoader` has dependency on `cheerio` from `npm`.\n",
    "\n",
    "```shell\n",
    "yarn add cheerio\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var Bedrock = require('@langchain/community/llms/bedrock').Bedrock;\n",
    "var ChatPromptTemplate = require('@langchain/core/prompts').ChatPromptTemplate;\n",
    "var createStuffDocumentsChain = require(\"langchain/chains/combine_documents\").createStuffDocumentsChain;\n",
    "\n",
    "var CheerioWebBaseLoader = require(\"@langchain/community/document_loaders/web/cheerio\").CheerioWebBaseLoader;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the `model` client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = new Bedrock({\n",
    "    model_id:'amazon.titan-text-express-v1',\n",
    "    temperature: 1,\n",
    "    maxTokenCount: 512,\n",
    "    topP: 0.9,\n",
    "    verbose: true\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompt with context placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var promptContexDynamic = ChatPromptTemplate.fromTemplate(`\n",
    "    Answer the user question.\n",
    "    Context: {context}\n",
    "    Question: {input}\n",
    "`);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a chain\n",
    "\n",
    "- We create a chain with prompt containing context, input placeholders and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var chainContextDynamic;\n",
    "\n",
    "createStuffDocumentsChain({\n",
    "    llm: model,\n",
    "    prompt: promptContexDynamic,\n",
    "}).then((chain) => chainContextDynamic = chain);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var input = \"What is LCEL ?\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var loader = new CheerioWebBaseLoader(\"https://python.langchain.com/v0.1/docs/expression_language/\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents\n",
    "\n",
    "- scrapes the web url and loads all content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var docs;\n",
    "\n",
    "loader.load().then((data) => docs = data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the web document loader has obtained by priting the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(docs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke LLM\n",
    "\n",
    "- given input we invoke LLM and get response on what LLM knows about LCEL by given extra context with information about LCEL\n",
    "- it is injected in invoke call as chain is a `documents` capable chain\n",
    "- documents are now dynamically loaded from web, nothing hardcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainContextDynamic.invoke({\n",
    "    input,\n",
    "    context: docs\n",
    "}).then((response) => console.log(response));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing problem\n",
    "\n",
    "- pricing is based on number of tokens\n",
    "- we are sending a lot of tokens, more than what is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(docs[0].pageContent.length);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4100+ characters for a very simple and basic page\n",
    "- all are being fed into the model query\n",
    "- we are charged for the tokens we provide / receive\n",
    "- a lot of wasted $$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split docs\n",
    "\n",
    "- instead of having one big string with all of the web page data, lets fragment it\n",
    "- not entire web page contains relevant information\n",
    "- split in chunks, only some chunks have relevant data\n",
    "- only send those chunks as context to model\n",
    "\n",
    "Let's import `RecursiveCharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var RecursiveCharacterTextSplitter = require(\"langchain/text_splitter\").RecursiveCharacterTextSplitter;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RecursiveCharacterTextSplitter`\n",
    "\n",
    "- `chunkSize`, how big is each chunk\n",
    "- `chunkOverlap`, how many characters to overlap in each chunk so some info is not split across chunks and lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var splitter = new RecursiveCharacterTextSplitter({\n",
    "    chunkSize: 300,\n",
    "    chunkOverlap: 30\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var splitDocs;\n",
    "\n",
    "splitter.splitDocuments(docs).then((data) => {\n",
    "    splitDocs = data;\n",
    "    console.log(splitDocs);\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke LLM\n",
    "\n",
    "- we send same dynamically loaded documents, but now they are split in chunks\n",
    "- total amount of characters/tokens is still the same ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainContextDynamic.invoke({\n",
    "    input,\n",
    "    context: splitDocs\n",
    "}).then((response) => console.log(response));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "20.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
